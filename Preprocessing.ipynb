{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This notebook encompasses all of the preprocessing which is need before the model is to be trained. This notebook implements two main functionalities. It should be noted that all of the playlists and their associated mood labels, which are already downloaded from Spotify contained in `train.csv`. \n",
    "\n",
    "The first functionality this notebook implements is to tokenize all the playlist descriptions, that is to assign each mood state a unique integer that will be used to generate the embedding later on. In addition, special tokens denoting the start of the sentence and the end of the sentence is inserted/appended to the start/end of the mood sequences, respectively. \n",
    "\n",
    "Secondly, this notebook also restructres the audio features, which, from Spotify, is a dictionary and contains a lot of extraneous data.  \n",
    "\n",
    "Lastly, the notebook converts all of the preprocessed data into an accessible data, where its entries are `json` encodings of the lists/preprocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all the unique moods\n",
    "\n",
    "The description of each playlist summarizes the mood that the playlist supposedly traverses. In short the format of these descriptions is described in the following:\n",
    "- Each **stage** – defined as an explicit state of moods the playlist wishes to traverse – of the playlist is deliminited by the word `to`, separated by spaces.\n",
    "- Each **stage** is the supplemented with additional mood descriptors, describing the state. These detailed descriptors are deliminited by a `,`. \n",
    "\n",
    "It should be noted that these mood descriptors are taken from [GEMS](https://www.zentnerlab.com/psychological-tests/geneva-emotional-music-scales) (Geneva Emotional Music Scale), which contains 45 labels. \n",
    "\n",
    "An example of this format is shown below:\n",
    "```\n",
    "agitated, nervous, irritated to fiery, energetic to inspired, moved to soothed, peaceful\n",
    "```\n",
    "A playlist with this description moves the user through 4 stages. The first stage is described through 3 mood keywords: `agitated, nervous, irritated`. The second stage is described through 2 mood keywords: `fiery, energetic`. The third stage is described using 2 mood keywords: `inspired, moved`. And lastly, the last stage is described using 2 mood keywords: `soothed, peaceful`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = json.load(open('playlist-tracks-features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moods = {}\n",
    "for i in features.keys():\n",
    "    if 'iso01' in i or 'iso02' in i:\n",
    "        continue\n",
    "    states = i[8:].split(' to ')\n",
    "    states = [s.lower().strip() for s in states]\n",
    "    states = [[x.lower().strip() for x in s.split(', ')] for s in states]\n",
    "    moods[i[:5]] = states\n",
    "print(moods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize mood states and location labels\n",
    "\n",
    "We now assign a unique integer to each mood keyword. Moreover, we also assign a unique integer to the meta-tokens: `<sos>`, `<eos`, `<pad>`. All of this is accomplished through the `Tokenizer` class as to encapsulate not only the functionalities of the tokenization process, but also to save the dictionaries associated with this particular tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \"\"\"\n",
    "    The tokenizer class provides three functionalities, \n",
    "    the first being the `fit_on_moods` methods. it extracts from \n",
    "    a list of moods which can be multi-leveled and nested, a unique list\n",
    "    of all the mood keywords. The second and third functionality\n",
    "    being that it is able to convert a list of states into the \n",
    "    corresponding token representation and back. We especially note\n",
    "    here that the tokenization, not only preseverse the order of the tokens\n",
    "    but also the structure of the list passed in. An example is given below:\n",
    "    [25, 2, [3, 4, [3, 5]]] -> [a, b [c, d, [c, e]]].\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        attr: stoi – defines the dictonary that converts the \n",
    "        mood words into their token representations.\n",
    "        attr: itos – defines the dictionary that converts token \n",
    "        representations back into the word-form representations.\n",
    "        \"\"\"\n",
    "        self.stoi = {}\n",
    "        self.itos = {}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.stoi)\n",
    "    \n",
    "    def fit_on_moods(self, moods):\n",
    "        \"\"\"\n",
    "        Given a list of words stored in a un/nested list `mood`, \n",
    "        `fit_on_moods` extracts the unique words and creates a \n",
    "        look up table that forms a bijection between the words\n",
    "        and a subset of the integers.\n",
    "        \"\"\"\n",
    "        flat = []\n",
    "        \n",
    "        Tokenizer.flatten(moods, flat)\n",
    "        vocab = sorted(set(flat))\n",
    "        vocab.append('<sos>')\n",
    "        vocab.append('<eos>')\n",
    "        vocab.append('<pad>')\n",
    "        for index, word in enumerate(vocab):\n",
    "            self.stoi[word] = index\n",
    "        self.itos = {v : k for k, v in self.stoi.items()}\n",
    "\n",
    "    def flatten(l, flat):\n",
    "        \"\"\"\n",
    "        Recursively, flatten the given list `l` into\n",
    "        a one-dimensional list that is appended to a given\n",
    "        list `flat`.\n",
    "        \"\"\"\n",
    "        if type(l) != list:\n",
    "            flat.append(l)\n",
    "        else:\n",
    "            for el in l:\n",
    "                Tokenizer.flatten(el, flat)\n",
    "\n",
    "    def moods_to_token(self, states, reverse=False):\n",
    "        \"\"\"\n",
    "        Recursively tokenize moods, while preserving the\n",
    "        structure of the list. When `reverse` is true, the\n",
    "        method translates the tokens back into the mood strings\n",
    "        \"\"\"\n",
    "        if type(states) != list:\n",
    "            if reverse:\n",
    "                return self.itos[states]\n",
    "            else:\n",
    "                return self.stoi[states]\n",
    "        else:\n",
    "            for index, state in enumerate(states):\n",
    "                states[index] = self.moods_to_token(state, reverse)\n",
    "            return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_moods(list(moods.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in moods.values():\n",
    "    tokenizer.moods_to_token(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing audio features\n",
    "We now want to organize the audio features into a single vector. Currently, the data for each playlist is organized into a list of songs. Each song is associated with a dictionary that contains the following data:\n",
    "```python\n",
    "{'danceability': 0.388,\n",
    "   'energy': 0.0859,\n",
    "   'key': 7,\n",
    "   'loudness': -16.061,\n",
    "   'mode': 0,\n",
    "   'speechiness': 0.0472,\n",
    "   'acousticness': 0.969,\n",
    "   'instrumentalness': 7.35e-05,\n",
    "   'liveness': 0.108,\n",
    "   'valence': 0.19,\n",
    "   'tempo': 88.253,\n",
    "   'type': 'audio_features',\n",
    "   'id': '30QNjcM3Q1GnLFIIJjWQL1',\n",
    "   'uri': 'spotify:track:30QNjcM3Q1GnLFIIJjWQL1',\n",
    "   'track_href': 'https://api.spotify.com/v1/tracks/30QNjcM3Q1GnLFIIJjWQL1',\n",
    "   'analysis_url': 'https://api.spotify.com/v1/audio-analysis/30QNjcM3Q1GnLFIIJjWQL1',\n",
    "   'duration_ms': 169410,\n",
    "   'time_signature': 3}\n",
    "```\n",
    "We note that there is a lot of data that we do not need, so the next few modules extracts the useful information storing them into a one-dimensional vector and discarding the \"useless\" data. Then all of the songs in the same playlist are appended into a larger array creating a 2-dimensional array:\n",
    "```python\n",
    "playlist = [ [song1 features],\n",
    "             [song2 features],\n",
    "             [     ...      ],\n",
    "                    .\n",
    "                    . \n",
    "                    .,\n",
    "           ]\n",
    "```\n",
    "\n",
    "Note that we also want to preserve the in which these features appear, so that training and evaluation is consistent, as well as the order of the songs relative to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = json.load(open('playlist-tracks-features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_features = ['danceability', 'energy', 'key', 'loudness', \n",
    "                   'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "                   'liveness', 'valence', 'tempo']\n",
    "def extract_features(songs):\n",
    "    \"\"\"\n",
    "    We extract the features of the songs of the same playlist\n",
    "    into a two dimesional array, if `l` is None, then None is returned.\n",
    "    \"\"\"\n",
    "    if songs == [None]:\n",
    "        return songs\n",
    "    songs_features = []\n",
    "    for song in songs:\n",
    "        # we first sort the keys so we retain the same order\n",
    "        # every time.\n",
    "        keys = sorted(song.keys())\n",
    "        song_features = []\n",
    "        for key in keys:\n",
    "            if key in useful_features:\n",
    "                song_features.append(song[key])\n",
    "        songs_features.append(song_features)\n",
    "    return songs_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for ease of storage, we change all of the two-dimesional arrays into `json` format and store these represetations accordingly back into the features dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "for k, v in tracks.items():\n",
    "    if k == 'iso01' or k == 'iso02':\n",
    "        continue\n",
    "    features[k[:5]] = json.dumps(extract_features(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine into dataframe\n",
    "Now with the mood states tokenized and the features discretized into vectors, we can store all of this into a Dataframe. Note that for readability, we also want to store the order of the features, which they were encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in moods.items():\n",
    "    moods[k] = json.dumps(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(features.values(), index=features.keys(), columns=['features'])\n",
    "df2 = pd.DataFrame(moods.values(), index=moods.keys(), columns=['moods_states'])\n",
    "df = df2.join(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tokenizer, 'tokenizer.pth')\n",
    "df.to_csv('train.csv')\n",
    "json.dump(sorted(useful_features), open('useful_features', 'w+'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
