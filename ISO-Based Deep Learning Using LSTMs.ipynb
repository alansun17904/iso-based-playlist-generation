{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISO-Based Deep Learning Using LSTMs\n",
    "\n",
    "This notebook establishes the model architecture that is used to learn the mapping between various desired mood states into playlists. The notebook is split into four distinct section: *data loading*, *dataset*, *model architecture*, and finally *training and evaluation*. We proceed by summarizing these sections briefly; a detailed description of their purposes can be found under the section headers. \n",
    "\n",
    "The **data loading** section loads all of the variables from preprocessing, including the tokenization of the training set, as well as the tokenizer used to perform the tokenizations. \n",
    "\n",
    "The **dataset** section creates an `ISODataset` class which converts the Dataframe loaded in from the data loading section to be in a format which is easily accessible by torch. \n",
    "\n",
    "The **model architecture** section creates the actual model that is used for training. The specification of the model is also under its section heading. It should be important to note that `torch lightning` is used throughout the notebook, but in particular for designing the model architecture. Thus, the code in the training and evaluation section is minimal. This section also encapsulates the loss function and learning rate scheduler used for training.\n",
    "\n",
    "The **training and evaluation** section contains code which kickstarts the training of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Data from preprocessing is loaded into this notebook – including the tokenizations, cleaned audio features, and the tokenizer itself. It is important to note that for ease of operation, we are pre-emptively removing all the rows in the data frame corresponding to empty playlists, as these are still WIP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', index_col=0)\n",
    "df = df[df['features'] != '[null]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        self.stoi = {}\n",
    "        self.itos = {}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.stoi)\n",
    "    \n",
    "    def fit_on_moods(self, moods):\n",
    "        flat = []\n",
    "        \n",
    "        Tokenizer.flatten(moods, flat)\n",
    "        vocab = sorted(set(flat))\n",
    "        vocab.append('<sos>')\n",
    "        vocab.append('<eos>')\n",
    "        vocab.append('<pad>')\n",
    "        for index, word in enumerate(vocab):\n",
    "            self.stoi[word] = index\n",
    "        self.itos = {v : k for k, v in self.stoi.items()}\n",
    "\n",
    "    def flatten(l, flat):\n",
    "        \"\"\"\n",
    "        Recursively, flatten a list.\n",
    "        \"\"\"\n",
    "        if type(l) != list:\n",
    "            flat.append(l)\n",
    "        else:\n",
    "            for el in l:\n",
    "                Tokenizer.flatten(el, flat)\n",
    "\n",
    "    def moods_to_token(self, states, reverse=False):\n",
    "        \"\"\"\n",
    "        Recursively tokenize moods, while preserving the\n",
    "        structure of the list. When `reverse` is true, the\n",
    "        method translates the tokens back into the mood strings\n",
    "        \"\"\"\n",
    "        if type(states) != list:\n",
    "            if reverse:\n",
    "                return self.itos[states]\n",
    "            else:\n",
    "                return self.stoi[states]\n",
    "        else:\n",
    "            for index, state in enumerate(states):\n",
    "                states[index] = self.moods_to_token(state, reverse)\n",
    "            return states\n",
    "tokenizer = torch.load('tokenizer.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "In this section, we package the training data into an `ISODataset` object. This is so that `torch`'s batching system can work with it more easily. Moreover, to make sure that all of the sequences are uniform, we assume that each states has at most 5 mood descriptors. Therefore, all the inputs to our network should be of shape `(batch_size, n, 5, 3)`, where $n$ is pre-determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISODataset(Dataset):\n",
    "    \"\"\"\n",
    "    The `ISODataset` class packages training data into a single index-able object.\n",
    "    This makes it easy for torch to use as a generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, maxlen=5):\n",
    "        \"\"\"\n",
    "        Initializer.\n",
    "        :param maxlen: The reader should note that this is the maximum number\n",
    "        of mood transitions there can be. The constants (5) proceeding this\n",
    "        block represent the number of descriptors allowed for each mood state.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.maxlen = maxlen\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        mood_states = json.loads(self.df.iloc[idx]['moods_states'])\n",
    "        for index, state in enumerate(mood_states):\n",
    "            mood_states[index] = np.pad(state, (0,5-len(state)), \n",
    "                                        constant_values=tokenizer.stoi['<pad>'])\n",
    "        while len(mood_states) < 5:\n",
    "            mood_states.append(np.full(5, tokenizer.stoi['<pad>']))\n",
    "        mood_states = torch.LongTensor(mood_states)\n",
    "        \n",
    "        audio_features = self.df.iloc[idx]['features']\n",
    "        audio_features = torch.Tensor(json.loads(audio_features))\n",
    "        return mood_states, audio_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the mood states are not only of variable length but also of variable dimension, we need to pad each batch so that a network will be able to process them. This preprocessing before it reaches the neural network is done through the `iso_collate` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iso_collate(batch):\n",
    "    moods, features, lengths = [], [], []\n",
    "    for data_point in batch:\n",
    "        moods.append(data_point[0])\n",
    "        features.append(data_point[1])\n",
    "        lengths.append(len(data_point[1]))\n",
    "    features = pad_sequence(features, batch_first=True)\n",
    "    moods = pad_sequence(moods, batch_first=True, padding_value=tokenizer.stoi['<pad>'])\n",
    "    return moods, torch.LongTensor(lengths), features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "The model is split into two distinct components: the attention mechanism, and the LSTM component. The interaction between these two components are shown in the figure below:\n",
    "\n",
    "![ISONet](imgs/isonet-lstm-attention-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    The attention mechanism of the network. On each time step, of the LSTM,\n",
    "    the LSTM cell looks at the previous hidden state as well as the input\n",
    "    to the LSTM, then it weights the various dimensions of the input based\n",
    "    on the hidden state / input. This is done by applying two linear on the\n",
    "    hidden and input states respectively, then combining the outputs, running\n",
    "    them through another linear layer, and interpolating the final weights \n",
    "    using the softmax function. The result of the attention layer, is a \n",
    "    sum product of all the weights and the respective attributes.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, attention_dim=40, maxlen=5):\n",
    "        \"\"\"\n",
    "        Initializer for the attention mechanism of the network.\n",
    "        :embed_dim: the dimension of the embeddings – hyperparamters.\n",
    "        :param attention_dim: specifies dimension of the hidden attention\n",
    "        layer. This is simply a hyperparameter and will only affect the\n",
    "        efficacy of the network, not its functionality. \n",
    "        :maxlen: specifies the maximum number of mood transitions allowed.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.embed_dim = embed_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        self.mood_attention = nn.Linear(self.embed_dim, self.attention_dim)\n",
    "        self.hidden_attention = nn.Linear(11, self.attention_dim)\n",
    "        # the input to the hidden attention is 11 as that is the size of the\n",
    "        # desired output dimension.\n",
    "        self.attention = nn.Linear(self.attention_dim, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, moods, hidden):\n",
    "        \"\"\"\n",
    "        :param moods: The raw input mood states – this is of size (bs x maxlen x 5 x embed_dim).\n",
    "        The reader should note that this *needs* to be preprocessed into the size\n",
    "        (bs x (maxlen * 5) x embed_dim). \n",
    "        :param hidden: The previous hidden state of the LSTM cell – this should be of\n",
    "        size (bs x 10).\n",
    "        The result of this function is to find a weighting, or alternatively, where to \n",
    "        pay \"attention\" to based on the `moods` and `hidden` state. The weights\n",
    "        of the attention, `alpha` of size (bs x (maxlen * 5)), is the used to in a sum product\n",
    "        with the moods (bs x (maxlen * 5) x embed_dim), yielding a size of (bs x embed_dim).\n",
    "        This single vector then acts as the inputs to the LSTM cell. \n",
    "        \"\"\"\n",
    "        att1 = self.mood_attention(moods)\n",
    "        att2 = self.hidden_attention(hidden)\n",
    "        att = self.attention(self.relu(att1 + att2.unsqueeze(1)))\n",
    "        alpha = self.softmax(att)\n",
    "        weighted_moods = (moods * alpha).sum(dim=1)\n",
    "        return weighted_moods, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    An attention-based, one-directional baseline model.\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer, dropout=0.0, maxlen=5, embed_dim=3, lr=1e-2,\n",
    "                 weight_decay=0.):\n",
    "        \"\"\"\n",
    "        Initializer.\n",
    "        :param tokenizer: the tokenizer used to create the tokenizations for\n",
    "        the mood states and descriptors. \n",
    "        :param dropout: the probability of dropout of the layer between the \n",
    "        hidden state and the final output of each LSTM cell.\n",
    "        :param maxlen: the maximum number of mood transition states that are allowed. \n",
    "        It should be noted that this must be greater than any of the number of the \n",
    "        states associated with each datapoint; otherwise, it will cause errors. \n",
    "        :param embed_dim: the dimensionality of each embedding.\n",
    "        :param lr: learning rate of the network, TODO: implement separate learning rates\n",
    "        for the attention network and the LSTM cell.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.maxlen = maxlen\n",
    "        self.tokenizer = tokenizer\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embedding = nn.Embedding(len(self.tokenizer.itos), self.embed_dim, \n",
    "                                      padding_idx=self.tokenizer.stoi['<pad>'])\n",
    "        self.attention = Attention(self.embed_dim)\n",
    "        self.h0 = nn.Linear(maxlen * self.embed_dim * 5, 11)\n",
    "        self.c0 = nn.Linear(maxlen * self.embed_dim * 5, 11)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstm = nn.LSTMCell(self.embed_dim, 11)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.forget = nn.Linear(11, self.embed_dim)\n",
    "        self.fc = nn.Linear(11, 11)\n",
    "        \n",
    "    def init_hidden_states(self, x):\n",
    "        \"\"\"\n",
    "        Given the mood states: flattened into a (bs x (maxlen * 5 * 3)) vector,\n",
    "        we use two separate linear layers to find the initial cell state and \n",
    "        initial hidden state. This is necessary over simply random initialization,\n",
    "        as the attention associated with the first cell is dependnet on h0.\n",
    "        \"\"\"\n",
    "        return self.h0(x), self.c0(x)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward feeding of the model. The network proceeds by first converting the mood\n",
    "        states into their respective embedding representations. Then, the flattened inputs\n",
    "        are used to determine the initial hidden/cell states of the given LSTM. The given\n",
    "        inputs are then sorted based on the length of their outputs. This makes it easier\n",
    "        for prediction. \n",
    "\n",
    "        :param x: a tuple that contains three items, the first being the various\n",
    "        mood states that are being queried, the second being the lenghts of the\n",
    "        desired labels of each datapoint, and finally the features – the target \n",
    "        outputs. \n",
    "        \"\"\"\n",
    "        mood_states, lengths, audio_features = x\n",
    "        bs = mood_states.size(0)\n",
    "        mood_states = self.embedding(mood_states)\n",
    "        moods = mood_states.view(bs, (self.maxlen * 5), self.embed_dim)\n",
    "        \n",
    "        sorted_lengths, indicies = lengths.sort(dim=0, descending=True)\n",
    "        moods, audio_features = moods[indicies], audio_features[indicies]\n",
    "        h, c = self.init_hidden_states(moods.view(bs, -1))  # (bs x 11)\n",
    "\n",
    "        predictions = torch.zeros(bs, max(lengths), 11)\n",
    "        for timestep in range(max(lengths)):\n",
    "            num_predict = sum([l > timestep for l in lengths])\n",
    "            attention_weighted_moods, alphas = self.attention(moods[:num_predict], \n",
    "                                                      h[:num_predict])\n",
    "            gate = self.sigmoid(self.forget(h[:num_predict]))\n",
    "            weighted_moods = gate * attention_weighted_moods\n",
    "            h, c = self.lstm(weighted_moods, \n",
    "                             (h[:num_predict], c[:num_predict]))\n",
    "            preds = self.fc(self.dropout(h))\n",
    "            \n",
    "            predictions[:num_predict, timestep, :] = preds\n",
    "        return predictions, audio_features\n",
    "    \n",
    "    def step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        One \"step\" of the model. \n",
    "        \"\"\"\n",
    "        predictions, targets = self(batch)\n",
    "        loss = F.mse_loss(predictions, targets)\n",
    "        return loss, {'loss': loss}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, logs = self.step(batch, batch_idx)\n",
    "        self.log_dict({f'train_{k}': v for k, v in logs.items()},\n",
    "                      on_step=True, on_epoch=True, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, logs = self.step(batch, batch_idx)\n",
    "        self.log_dict({f'val_{k}': v for k, v in logs.items()}, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configuration of the optimizer used to train the model.\n",
    "        This method is implicitly called by torch lightning during training. \n",
    "        Note that the learning rate and weight decay is given by the initialization\n",
    "        parameters of the model. \n",
    "        TODO: Implement an appropriate learning rate scheduler. \n",
    "        \"\"\"\n",
    "        return optim.SGD(self.parameters(), lr=self.lr,\n",
    "                         weight_decay=self.weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation\n",
    "This section is simplified by the torch lightning interface. Parameters involving training including epochs as well as checkpoints are paramterized in the initialization of `Trainer` object. We note here that there is no validation set as there are too little data points. Therefore, all the data is being used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = ISODataset(df)\n",
    "train_loader = DataLoader(iso,\n",
    "                          batch_size=4,\n",
    "                          collate_fn=iso_collate)\n",
    "model = Model(tokenizer, embed_dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 96    \n",
      "1 | attention | Attention | 681   \n",
      "2 | h0        | Linear    | 836   \n",
      "3 | c0        | Linear    | 836   \n",
      "4 | dropout   | Dropout   | 0     \n",
      "5 | lstm      | LSTMCell  | 704   \n",
      "6 | sigmoid   | Sigmoid   | 0     \n",
      "7 | forget    | Linear    | 36    \n",
      "8 | fc        | Linear    | 132   \n",
      "----------------------------------------\n",
      "3.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.3 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc80ea96f714aaabb20a949c848fe83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=100)\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
